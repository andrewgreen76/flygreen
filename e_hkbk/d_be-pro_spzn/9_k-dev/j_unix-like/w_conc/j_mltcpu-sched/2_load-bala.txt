
Load balancing :
 . ensuring that workload on every CPU is a fair and (roughly) equal amount 


"
Load balancing is the process of distributing computational workloads or network traffic across multiple resources, such as servers, processors, or network links, to ensure optimal resource utilization, minimize response time, and avoid overload on any single resource. Load balancing is a crucial concept in distributed computing, cloud computing, and networking environments where multiple entities work together to handle requests or tasks.

The primary goals of load balancing include:

1. **Even Distribution of Workload:**
   - Distributing the incoming workload evenly across available resources helps prevent individual resources from becoming overloaded, ensuring a balanced utilization of resources.

2. **Maximizing Throughput:**
   - Load balancing aims to maximize the overall throughput or processing capacity of the system by efficiently utilizing all available resources.

3. **Reducing Response Time:**
   - By evenly distributing the workload, load balancing can help reduce the response time for individual requests or tasks, providing better performance to end-users.

4. **Enhancing Scalability:**
   - Load balancing supports scalability by allowing additional resources to be added to the system as needed, accommodating increased demand without causing performance degradation.

Load balancing can be applied in various contexts:

1. **Server Load Balancing:**
   - In web server farms or cloud environments, server load balancing distributes incoming web traffic or requests across multiple servers to prevent any single server from being overwhelmed.

2. **Processor Load Balancing:**
   - In parallel computing or multicore systems, processor load balancing distributes computational tasks among available processors to maximize parallel processing capabilities.

3. **Network Load Balancing:**
   - In networking, load balancing distributes network traffic across multiple paths or links to avoid congestion and optimize the utilization of network resources.

4. **Application Load Balancing:**
   - Load balancing can be applied at the application level, where requests for a specific service or application are distributed across multiple instances or nodes.

5. **Global Load Balancing:**
   - In distributed systems spanning multiple geographic locations, global load balancing optimizes the distribution of workloads to different data centers or regions.

Load balancing can be achieved through various algorithms and techniques, including:

- **Round Robin:** Distributes requests or tasks in a circular order.
- **Weighted Round Robin:** Assigns different weights to resources based on their capacity or capability.
- **Least Connections:** Routes requests to the server with the fewest active connections.
- **Least Response Time:** Routes requests to the server with the lowest response time.
- **Hash-based Load Balancing:** Uses a hash function to map requests to specific resources based on request characteristics.

Load balancing is a critical component for achieving high availability, scalability, and efficient resource utilization in distributed systems.
"
====================================================================================================================
====================================================================================================================
====================================================================================================================
"
Load Balancing in Multi-Queue Multiprocessor Schedulers:
 . Methods to achieve optimal workload distribution among CPUs, ensuring efficient utilization of resources.
"
_
